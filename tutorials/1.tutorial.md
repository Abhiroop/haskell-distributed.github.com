---
layout: tutorial
categories: tutorial
title: Getting Started
---

### Getting Started <a class="pull-right" href="http://hackage.haskell.org/platform" ><img src="http://hackage.haskell.org/platform/icons/button-64.png"></a>

-----

Please note that this tutorial is a work in progress. We highly recommend
reading the haddock documentation and reading the Well-Typed blog, which
are offer the best quality sources of information at this time.

In order to go through this tutorial you will need a Haskell development
environment and we recommend installing the latest version of the
[Haskell Platform](www.haskell.org/platform/) if you've not done
so already.

Once you're up and running, you'll want to get hold of the distributed-process
library and a choice of network transport backend. This guide will use
the network-transport-tcp backend, but the simplelocalnet or inmemory
backends are also available on github, along with some other experimental
options.

### Creating Nodes

Cloud Haskell's *lightweight processes* reside on a 'node', which must
be initialised with a network transport implementation and a remote table.
The latter is required so that physically separate nodes can identify known
objects in the system (such as types and functions) when receiving messages
from other nodes. We'll look at inter-node communication later, so for now
it will suffice to pass the default remote table, which defines the built-in
stuff Cloud Haskell needs at a minimum.

Our TCP network transport backend needs an IP address and port to get started
with, and we're good to go...

{% highlight haskell %}
main :: IO ()
main = do
  Right (t, _) <- createTransport "127.0.0.1" "10501" defaultTCPParameters
  node <- newLocalNode t initRemoteTable
  ....
{% endhighlight %}

And now we have a running node.

### Messages

We can start a new lightweight process with `forkProcess`, which takes a node,
a `Process` action - because our concurrent code will run in the `Process`
monad - and returns an address for the process in the form of a `ProcessId`.
The process id can be used to send messages to the running process - here we
will send one to ourselves!

{% highlight haskell %}
-- in main
  _ <- forkProcess node $ do
      -- get our own process id
      self <- getSelfPid
      send self "hello"
      hello <- expect :: Process String
      liftIO $ putStrLn hello
      return ()
{% endhighlight %}

Lightweight processes are implemented as `forkIO` threads. In general we will
try to forget about this implementation detail, but for now just note that we
haven't deadlocked ourself by sending to and receiving from our own mailbox
in this fashion. Sending a message is a completely asynchronous operation - even
if the recipient doesn't exist, no error will be raised and evaluating `send`
will not block the caller.

Receiving messages works the other way around, blocking the caller until a message
matching the expected type arrives in the process (conceptual) mailbox.
If multiple messages of that type are in the queue, they will be returned in FIFO
order, otherwise the caller will be blocked until a message arrives that can be
decoded to the correct type.

Let's spawn another process on the same node and make the two talk to each other.

{% highlight haskell %}
main :: IO ()
main = do
  Right (t, _) <- createTransport "127.0.0.1" "10501" defaultTCPParameters
  node <- newLocalNode t initRemoteTable
  _ <- forkProcess node $ do
      echoPid <- spawnLocal $ forever $ do
          r <- receiveWait [
              match (\((sender :: ProcessId), (msg :: String)) -> send sender msg >> return ())
            , match (\(m :: String) -> say $ "printing " ++ m)
            ]
      -- send some messages!
      self <- getSelfPid
      send (self, "hello")
      m <- expectTimeout 1000000
      case m of
        Nothing  -> die "nothing came back!"
        (Just s) -> say $ "got back " ++ s
{% endhighlight %}

Note that we've used a `receive` class of function this time around. The `match`
construct allows you to construct a list of potential message handling code and
have them evaluated against incoming messages. The first match indicates that,
given a tuple `t :: (ProcessId, String)` that we will send the `String` component
back to the sender's `ProcessId`. The second match prints out whatever string it
receives.

Also note the use of a 'timeout' (given in microseconds), which is available for
both the `expect` and `receive` variants. This returns `Nothing` unless a message
can be dequeued from the mailbox within the specified time interval.

### Serializable

Processes can send data if the type implements the `Serializable` typeclass, which is
done indirectly by implementing `Binary` and deriving `Typeable`. Implementations are
already provided for primitives and some commonly used data structures.

### Typed Channels

Channels provides an alternative to message transmission with `send` and `expect`.
While `send` and `expect` allow  transmission of messages of any `Serializable`
type, channels require a uniform type. Channels work like a distributed equivalent
of Haskell's `Control.Concurrent.Chan`, however they have distinct ends: a single
receiving port and a corollary send port.

Channels provide a nice alternative to *bare send and receive*, which is a bit
*unHaskellish*, because the processes message queue has messages of multiple
types, and we have to do dynamic type checking.

We create channels with a call to `newChan`, and send/receive on them using the
`{send,receive}Chan` primitives:

{% highlight haskell %}
channelsDemo :: Process ()
channelsDemo = do
    (sp, rp) <- newChan :: Process (SendPort String, ReceivePort String)
    
    -- send on a channel
    spawnLocal $ sendChan sp "hello!"
    
    -- receive on a channel
    m <- receiveChan rp
    say $ show m
{% endhighlight %}

Channels are particularly useful when you are sending a message that needs a
response, because the code that receives the response knows exactly where it
came from. Channels can sometimes allows message types to be simplified, as
passing a `ProcessId` to reply to isn't required. Channels are not so useful
when you need to spawn a process and then send a bunch a messages to it and
wait for replies, because we canâ€™t send the `ReceivePort`.

ReceivePorts can be merged, so you can listen on several simultaneously. In the
latest version of [distributed-process][2], you can listen for *regular* messages
and on multiple channels at the same time, using `matchChan` in the list of
allowed matches passed `receive`.

The [Control.Distributed.Process.Platform.Async][3] API provides an alternative
type safe mechanism for receiving data in request/reply scenarios. This relies
on spawning insulating processes and using either channels or STM internally,
so whilst it provides a neat API, there are some overheads involved. The
`ManagedProcess` API uses this mechanism to great effect for dealing with
client/server style interactions. See the [ManagedProcess.Client][4] APIs and
platform [documentation](/documentation.html) for further details.

### Linking and monitoring

Processes can be linked to other processes, nodes or channels. Links are unidirectional,
and guarantee that once the linked object *dies*, the linked process will also be
terminated. Monitors do not cause the *listening* process to exit, but rather they
put a `ProcessMonitorNotification` into the process' mailbox.

### Spawning Remote Processes

In order to spawn a process on a node we need something of type `Closure (Process ())`.
In distributed-process if `f : T1 -> T2` then

{% highlight haskell %}
  $(mkClosure 'f) :: T1 -> Closure T2
{% endhighlight %}

That is, the first argument the function we pass to mkClosure will act as the closure
environment for that process; if you want multiple values in the closure environment,
you must tuple them up.

In order to spawn a process remotely we will need to configure the remote table
(see the documentation for more details) and the easiest way to do this, is to
let the library generate the relevant code for us. For example (taken from the
distributed-process-platform test suites):

{% highlight haskell %}
sampleTask :: (TimeInterval, String) -> Process String
sampleTask (t, s) = sleep t >> return s

$(remotable ['sampleTask])
{% endhighlight %}

We can now create a closure environment for `sampleTask` like so:

{% highlight haskell %}
($(mkClosure 'sampleTask) (seconds 2, "foobar"))
{% endhighlight %}

The call to `remotable` generates a remote table and generates a definition
`__remoteTable :: RemoteTable -> RemoteTable` in our module for us. We can
compose this with other remote tables in order to come up with a final, merged
remote table for use in our program:

{% highlight haskell %}
myRemoteTable :: RemoteTable
myRemoteTable = Main.__remoteTable initRemoteTable

main :: IO ()
main = do
 localNode <- newLocalNode transport myRemoteTable
 -- etc
{% endhighlight %}

### Stopping Processes

Some processes, like the *outer* process in the previous example, will run until
they've completed and then return their value. This is just as we find with IO action,
and there is an instance of `MonadIO` for the `Process` monad, so you can `liftIO` if you
need to evaluate IO actions.

Because processes are implemented with `forkIO` we might be tempted to stop
them by throwing an asynchronous exception to the process, but this is almost
certainly the wrong thing to do. Instead we might send a kind of poison pill,
which the process *ought* to handle by shutting down gracefully. Unfortunately
because of the asynchronous nature of sending, this is no good because `send`
will not fail under any circumstances. In fact, because `send` doesn't block,
we therefore have no way to no if the recipient existed at the time we sent the
poison pill. Even if the recipient did exist, we still have no guarantee that
the message we sent actually arrived - the network connection between the nodes
could have broken, for example. Making this *shutdown* protocol synchronous is
no good either - how long would we wait for a reply? Indefinitely?

Exit signals come in two flavours - those that can
be caught and those that cannot. A call to
`exit :: (Serializable a) => ProcessId -> a -> Process ()` will dispatch an
exit signal to the specified process. These *signals* can be intercepted and
handled by the destination process however, so if you need to terminate the
process in a brutal way, you can use the `kill :: ProcessId -> String -> Process ()`
function, which sends an exit signal that cannot be handled.

------
#### __An important note about exit signals__

Exit signals in Cloud Haskell are unlike asynchronous exceptions in regular
haskell code. Whilst processes *can* use asynchronous exceptions - there's
nothing stoping this since the `Process` monad is an instance of `MonadIO` -
exceptions thrown are not bound by the same ordering guarantees as messages
delivered to a process. Link failures and exit signals *might* be implemented
using asynchronous exceptions - that is the case in the current
implementation - but these are implemented in such a fashion that if you
send a message and *then* an exit signal, the message is guaranteed to arrive
first.

You should avoid throwing your own exceptions in code where possible. Instead,
you should terminate yourself, or another process, using the built-in primitives
`exit`, `kill` and `die`.

{% highlight haskell %}
exit pid reason  -- force `pid` to exit - reason can be any `Serializable` message
kill pid reason  -- reason is a string - the *kill* signal cannot be caught
die reason       -- as 'exit' but kills *us*
{% endhighlight %}

The `exit` and `kill` primitives do essentially the same thing, but catching
the specific exception thrown by `kill` is impossible, making `kill` an
*untrappable exit signal*. Of course you could trap **all** exceptions, but
you already know that's a very bad idea right!?

The `exit` primitive is a little different. This provides support for trapping
exit signals in a generic way, so long as your *exit handler* is able to
recognise the underlying type of the 'exit reason'. This (reason for exiting)
is stored as a raw `Message`, so if your handler takes the appropriate type
as an input (and therefore the `Message` can be decoded and passed to the
handler) then the handler will run. This is pretty much the same approach as
exception handling using `Typeable`, except that we decide whether or not the
exception can be handled based on the type of `reason` instead of the type of
the exception itself.

Calling `die` will immediately raise an exit signal (i.e., `ProcessExitException`)
in the calling process.

------

[1]: /static/doc/distributed-process/Control-Distributed-Process.html#v:Message
[2]: http://hackage.haskell.org/package/distributed-process
[3]: /static/doc/distributed-process-platform/Control-Distributed-Process-Platform-Async.html
[4]: /static/doc/distributed-process-platform/Control-Distributed-Process-Platform-ManagedProcess.htmlv:callAsync
